{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13ca0c70-1830-498b-b080-160c554306d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install numpy pandas matplotlib seaborn scipy openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d72bfd90-39b9-482a-bdfb-782a90456b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Настройка отображения\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62031a3c-d99f-4732-90d7-be332f42f110",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instr</th>\n",
       "      <th>class</th>\n",
       "      <th>nb.repeat</th>\n",
       "      <th>attendance</th>\n",
       "      <th>difficulty</th>\n",
       "      <th>Q1</th>\n",
       "      <th>Q2</th>\n",
       "      <th>Q3</th>\n",
       "      <th>Q4</th>\n",
       "      <th>Q5</th>\n",
       "      <th>Q6</th>\n",
       "      <th>Q7</th>\n",
       "      <th>Q8</th>\n",
       "      <th>Q9</th>\n",
       "      <th>Q10</th>\n",
       "      <th>Q11</th>\n",
       "      <th>Q12</th>\n",
       "      <th>Q13</th>\n",
       "      <th>Q14</th>\n",
       "      <th>Q15</th>\n",
       "      <th>Q16</th>\n",
       "      <th>Q17</th>\n",
       "      <th>Q18</th>\n",
       "      <th>Q19</th>\n",
       "      <th>Q20</th>\n",
       "      <th>Q21</th>\n",
       "      <th>Q22</th>\n",
       "      <th>Q23</th>\n",
       "      <th>Q24</th>\n",
       "      <th>Q25</th>\n",
       "      <th>Q26</th>\n",
       "      <th>Q27</th>\n",
       "      <th>Q28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   instr  class  nb.repeat  attendance  difficulty  Q1  Q2  Q3  Q4  Q5  Q6  Q7  Q8  Q9  Q10  Q11  Q12  Q13  Q14  Q15  Q16  Q17  Q18  Q19  Q20  Q21  Q22  Q23  Q24  Q25  Q26  Q27  Q28\n",
       "0      1      2          1           0           4   3   3   3   3   3   3   3   3   3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3\n",
       "1      1      2          1           1           3   3   3   3   3   3   3   3   3   3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3\n",
       "2      1      2          1           2           4   5   5   5   5   5   5   5   5   5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5\n",
       "3      1      2          1           1           3   3   3   3   3   3   3   3   3   3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3    3\n",
       "4      1      2          1           0           1   1   1   1   1   1   1   1   1   1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
       "5      1      2          1           3           3   4   4   4   4   4   4   4   4   4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4\n",
       "6      1      2          1           1           3   4   4   4   4   4   4   4   4   4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4    4\n",
       "7      1      2          1           1           3   5   5   5   5   5   5   5   5   5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5    5"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"turkiye.csv\")\n",
    "\n",
    "df.head(8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4ed13e1-4046-41a9-98da-471f5a9f7bb9",
   "metadata": {},
   "source": [
    "## Удаляем выбросы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f76937ff-0c69-4158-a343-98b3bfe0dc43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Студентов с ≥26 одинаковыми ответами: 3409\n",
      "Студентов с посещаемостью < 2: 2930\n",
      "\n",
      "Распределение по Attendance\n",
      "attendance\n",
      "0    1902\n",
      "1    1028\n",
      "2     792\n",
      "3    1252\n",
      "4     846\n",
      "\n",
      "Распределение по Attendance среди записей с ≥26 одинаковыми ответами:\n",
      "attendance\n",
      "0    1292\n",
      "1     599\n",
      "2     434\n",
      "3     624\n",
      "4     460\n",
      "Число записей с ≥27 одинаковыми ответами ИЛИ посещаемостью < 2: 4448\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"turkiye.csv\")\n",
    "\n",
    "# Вопросы Q1–Q28\n",
    "q_cols = [f'Q{i}' for i in range(1, 29)]\n",
    "\n",
    "# Функция: ≥26 одинаковых ответов\n",
    "def has_too_many_identical_answers(row):\n",
    "    return row.value_counts().max() >= 26\n",
    "\n",
    "# Маска аномальных ответов\n",
    "mask_identical = df[q_cols].apply(has_too_many_identical_answers, axis=1)\n",
    "\n",
    "# Подсчёты\n",
    "n_identical = mask_identical.sum()\n",
    "n_low_attendance = (df['attendance'] < 2).sum()\n",
    "\n",
    "# Распределение по Attendance\n",
    "dist_attendance_all = df['attendance'].value_counts().sort_index()\n",
    "\n",
    "# Распределение по Attendance среди \"одинаковых\" записей\n",
    "dist_attendance = df[mask_identical]['attendance'].value_counts().sort_index()\n",
    "\n",
    "# Вывод\n",
    "print(f\"Студентов с ≥26 одинаковыми ответами: {n_identical}\")\n",
    "print(f\"Студентов с посещаемостью < 2: {n_low_attendance}\")\n",
    "\n",
    "print(\"\\nРаспределение по Attendance\")\n",
    "print(dist_attendance_all.to_string())\n",
    "\n",
    "print(\"\\nРаспределение по Attendance среди записей с ≥26 одинаковыми ответами:\")\n",
    "print(dist_attendance.to_string())\n",
    "\n",
    "mask_A = df[q_cols].apply(has_too_many_identical_answers, axis=1)\n",
    "mask_B = df['attendance'] < 2\n",
    "\n",
    "# Пересечение\n",
    "mask_intersection = mask_A | mask_B\n",
    "n_intersection = mask_intersection.sum()\n",
    "\n",
    "print(f\"Число записей с ≥27 одинаковыми ответами ИЛИ посещаемостью < 2: {n_intersection}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2a74b64-2d18-4a9d-af65-fc45e6d459dd",
   "metadata": {},
   "source": [
    "### Повторы и одинаковые ответы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d3110eb-27b6-4ea6-9f3c-16c9ae1eea43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Исходное количество строк: 5820\n",
      "Удалено строк с ≥26 одинаковыми ответами: 3409\n",
      "Удалено строк с посещаемостью ниже 2: 1039\n",
      "Итоговое количество строк после очистки: 1372\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"turkiye.csv\")\n",
    "\n",
    "print(f\"Исходное количество строк: {len(df)}\")\n",
    "\n",
    "# Колонки с вопросами Q1–Q28\n",
    "q_cols = [f'Q{i}' for i in range(1, 29)]\n",
    "\n",
    "# 1. Удаляем строки, где 27 или более ответов одинаковые\n",
    "def has_too_many_identical_answers(row):\n",
    "    # Считаем частоту каждого значения в строке\n",
    "    value_counts = row.value_counts()\n",
    "    # Если максимальная частота >= 26 — считаем аномалией\n",
    "    # print(value_counts)\n",
    "    # print(value_counts.max() >= 26)\n",
    "    # print('-'*10)\n",
    "    return value_counts.max() >= 26\n",
    "\n",
    "mask_identical = df[q_cols].apply(has_too_many_identical_answers, axis=1)\n",
    "# df[mask_identical].to_excel('удалённые_одинаковые_ответы2.xlsx', index=False)\n",
    "\n",
    "removed_identical = mask_identical.sum()\n",
    "df = df[~mask_identical].copy()\n",
    "\n",
    "print(f\"Удалено строк с ≥26 одинаковыми ответами: {removed_identical}\")\n",
    "\n",
    "\n",
    "# 2. Удаляем записи с посещаемостью ниже 2 (Attendance < 2)\n",
    "# Согласно описанию, Attendance ∈ {0,1,2,3,4}\n",
    "removed_low_attendance = (df['attendance'] < 2).sum()\n",
    "df = df[df['attendance'] >= 2].copy()\n",
    "\n",
    "print(f\"Удалено строк с посещаемостью ниже 2: {removed_low_attendance}\")\n",
    "print(f\"Итоговое количество строк после очистки: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2537f1d-9203-4bc0-b5de-09d3654f208f",
   "metadata": {},
   "source": [
    "### Поиск выбросов по квартилям (метод IQR) — по каждому признаку отдельно"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "225ccd01-1317-4a57-b894-a51e6245ef07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число выбросов, обнаруженных методом IQR: 349\n",
      "Итоговое количество строк после очистки: 1023\n"
     ]
    }
   ],
   "source": [
    "k = 1.5\n",
    "outlier_mask_iqr = pd.Series([False] * len(df), index=df.index)\n",
    "\n",
    "for col in q_cols:\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - k * IQR\n",
    "    upper_bound = Q3 + k * IQR\n",
    "    outlier_mask_iqr |= (df[col] < lower_bound) | (df[col] > upper_bound)\n",
    "\n",
    "n_outliers_iqr = outlier_mask_iqr.sum()\n",
    "\n",
    "df = df[~outlier_mask_iqr].copy()\n",
    "\n",
    "print(f\"Число выбросов, обнаруженных методом IQR: {n_outliers_iqr}\")\n",
    "print(f\"Итоговое количество строк после очистки: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f08d6210-39aa-456b-9ddb-9c05dbc3b6e8",
   "metadata": {},
   "source": [
    "## Корреляции"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99778cb6-7874-4a96-bdab-6d1c9d3e9070",
   "metadata": {},
   "source": [
    "### Общая матрица корреляции"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb43305-73bf-43c2-97a8-c4408bae3b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# ПОЛНАЯ МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ВСЕХ ЧИСЛОВЫХ ПРИЗНАКОВ\n",
    "# ============================================================\n",
    "\n",
    "# Выбираем все числовые колонки (включая дополнительные признаки)\n",
    "q_cols = [f'Q{i}' for i in range(1, 29)]\n",
    "numeric_cols = ['instr', 'class', 'nb.repeat', 'attendance', 'difficulty'] + q_cols\n",
    "\n",
    "# Проверяем наличие всех колонок\n",
    "available_cols = [col for col in numeric_cols if col in df.columns]\n",
    "print(f\"Числовые признаки для корреляции ({len(available_cols)} колонок):\")\n",
    "print(available_cols)\n",
    "print()\n",
    "\n",
    "# Вычисление полной матрицы корреляций\n",
    "correlation_matrix_full = df[available_cols].corr()\n",
    "\n",
    "# Вывод полной матрицы\n",
    "print(\"=\" * 120)\n",
    "print(\"ПОЛНАЯ МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ВСЕХ ПРИЗНАКОВ\")\n",
    "print(\"=\" * 120)\n",
    "print(correlation_matrix_full.to_string())\n",
    "\n",
    "# Сохранение в CSV\n",
    "correlation_matrix_full.to_csv('correlation_matrix_all_features.csv')\n",
    "print(\"\\n✓ Матрица корреляций сохранена в 'correlation_matrix_all_features.csv'\")\n",
    "\n",
    "# Описательная статистика\n",
    "mask = np.triu(np.ones_like(correlation_matrix_full, dtype=bool), k=1)\n",
    "upper_triangle = correlation_matrix_full.where(mask)\n",
    "correlations = upper_triangle.stack()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"СТАТИСТИКА КОРРЕЛЯЦИЙ\")\n",
    "print(\"=\" * 120)\n",
    "print(f\"Количество пар признаков: {len(correlations)}\")\n",
    "print(f\"Средняя корреляция: {correlations.mean():.4f}\")\n",
    "print(f\"Медианная корреляция: {correlations.median():.4f}\")\n",
    "print(f\"Минимальная корреляция: {correlations.min():.4f}\")\n",
    "print(f\"Максимальная корреляция: {correlations.max():.4f}\")\n",
    "print(f\"Стандартное отклонение: {correlations.std():.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ВИЗУАЛИЗАЦИЯ 1: Полная матрица\n",
    "# ============================================================\n",
    "\n",
    "plt.figure(figsize=(24, 22))\n",
    "sns.heatmap(correlation_matrix_full, \n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            annot_kws={'size': 7},  # Размер шрифта для чисел\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.title('Полная матрица корреляций для всех признаков датасета', \n",
    "          fontsize=18, pad=20, weight='bold')\n",
    "plt.xlabel('Признаки', fontsize=14)\n",
    "plt.ylabel('Признаки', fontsize=14)\n",
    "plt.xticks(rotation=90, fontsize=9)\n",
    "plt.yticks(rotation=0, fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_matrix_all_features.png', dpi=300, bbox_inches='tight')\n",
    "print(\"\\n✓ Визуализация сохранена в 'correlation_matrix_all_features.png'\")\n",
    "\n",
    "# ============================================================\n",
    "# ВИЗУАЛИЗАЦИЯ 2: Корреляции дополнительных признаков с вопросами\n",
    "# ============================================================\n",
    "\n",
    "# Матрица корреляций\n",
    "additional_features = ['instr', 'class', 'nb.repeat', 'attendance', 'difficulty']\n",
    "available_additional = [col for col in additional_features if col in df.columns]\n",
    "\n",
    "# Создаём подматрицу\n",
    "corr_additional_vs_questions = df[available_additional + q_cols].corr()\n",
    "corr_subset = corr_additional_vs_questions.loc[available_additional, q_cols]\n",
    "\n",
    "plt.figure(figsize=(18, 6))\n",
    "sns.heatmap(corr_subset, \n",
    "            annot=True,\n",
    "            fmt='.2f',\n",
    "            cmap='coolwarm',\n",
    "            center=0,\n",
    "            vmin=-1, vmax=1,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={\"shrink\": 0.8})\n",
    "\n",
    "plt.title('Корреляция дополнительных признаков с вопросами оценки (Q1-Q28)', \n",
    "          fontsize=16, pad=15, weight='bold')\n",
    "plt.xlabel('Вопросы', fontsize=12)\n",
    "plt.ylabel('Дополнительные признаки', fontsize=12)\n",
    "plt.xticks(rotation=90)\n",
    "plt.tight_layout()\n",
    "plt.savefig('correlation_additional_features_vs_questions.png', dpi=300, bbox_inches='tight')\n",
    "print(\"✓ Визуализация сохранена в 'correlation_additional_features_vs_questions.png'\")\n",
    "\n",
    "# ============================================================\n",
    "# АНАЛИЗ КОРРЕЛЯЦИЙ ДОПОЛНИТЕЛЬНЫХ ПРИЗНАКОВ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"КОРРЕЛЯЦИЯ ДОПОЛНИТЕЛЬНЫХ ПРИЗНАКОВ С ВОПРОСАМИ\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "for feature in available_additional:\n",
    "    print(f\"\\n{feature.upper()}:\")\n",
    "    corr_values = correlation_matrix_full.loc[feature, q_cols].sort_values(ascending=False)\n",
    "    print(f\"  Топ-5 наиболее сильных корреляций:\")\n",
    "    for q, val in corr_values.head(5).items():\n",
    "        print(f\"    {q}: {val:.4f}\")\n",
    "    print(f\"  Топ-5 наиболее слабых корреляций:\")\n",
    "    for q, val in corr_values.tail(5).items():\n",
    "        print(f\"    {q}: {val:.4f}\")\n",
    "\n",
    "# ============================================================\n",
    "# ТОП КОРРЕЛЯЦИЙ МЕЖДУ ВСЕМИ ПРИЗНАКАМИ\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"ТОП-15 САМЫХ СИЛЬНЫХ ПОЛОЖИТЕЛЬНЫХ КОРРЕЛЯЦИЙ (ВСЕ ПРИЗНАКИ)\")\n",
    "print(\"=\" * 120)\n",
    "\n",
    "corr_pairs_all = []\n",
    "for i in range(len(correlation_matrix_full.columns)):\n",
    "    for j in range(i+1, len(correlation_matrix_full.columns)):\n",
    "        corr_pairs_all.append({\n",
    "            'Признак 1': correlation_matrix_full.columns[i],\n",
    "            'Признак 2': correlation_matrix_full.columns[j],\n",
    "            'Корреляция': correlation_matrix_full.iloc[i, j]\n",
    "        })\n",
    "\n",
    "corr_df_all = pd.DataFrame(corr_pairs_all)\n",
    "corr_df_all_sorted = corr_df_all.sort_values('Корреляция', ascending=False)\n",
    "\n",
    "print(corr_df_all_sorted.head(15).to_string(index=False))\n",
    "corr_df_all_sorted.to_csv('correlation_pairs_all_features.csv', index=False)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"ТОП-15 САМЫХ СЛАБЫХ КОРРЕЛЯЦИЙ (ВСЕ ПРИЗНАКИ)\")\n",
    "print(\"=\" * 120)\n",
    "print(corr_df_all_sorted.tail(15).to_string(index=False))\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\" * 120)\n",
    "print(\"АНАЛИЗ ЗАВЕРШЁН\")\n",
    "print(\"=\" * 120)\n",
    "print(\"\\nСозданные файлы:\")\n",
    "print(\"1. correlation_matrix_all_features.csv - полная матрица корреляций\")\n",
    "print(\"2. correlation_matrix_all_features.png - визуализация полной матрицы\")\n",
    "print(\"3. correlation_additional_features_vs_questions.png - доп. признаки vs вопросы\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e33529-996b-4781-b1d7-f58cd5a9f579",
   "metadata": {},
   "source": [
    "### Матрица корреляции для предметов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7da44bfc-aaf7-495a-88ee-4d614bedca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Распределение по предметам:\n",
      "Предмет      1   2    3   4    5   6   7    8   9  10  11  12   13\n",
      "Количество  62  14  112  35  135  99  47  147  98  67  90   7  110\n"
     ]
    }
   ],
   "source": [
    "class_counts = df['class'].value_counts().sort_index()\n",
    "class_df = pd.DataFrame({\n",
    "    'Предмет': class_counts.index,\n",
    "    'Количество': class_counts.values\n",
    "})\n",
    "\n",
    "# Транспонирование для вывода в строку\n",
    "print(\"Распределение по предметам:\")\n",
    "print(class_df.T.to_string(header=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bcb83ca-5f0f-43f5-9253-afdf222c3767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['nb.repeat', 'attendance', 'difficulty', 'Q1', 'Q2', 'Q3', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8', 'Q9', 'Q10', 'Q11', 'Q12', 'Q13', 'Q14', 'Q15', 'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26', 'Q27', 'Q28']\n",
      "\n",
      "========================================================================================================================\n",
      "МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ПРЕДМЕТА 3 (n=112)\n",
      "========================================================================================================================\n",
      "            nb.repeat  attendance  difficulty        Q1        Q2        Q3        Q4        Q5        Q6        Q7        Q8        Q9       Q10       Q11       Q12       Q13       Q14       Q15       Q16       Q17       Q18       Q19       Q20       Q21       Q22       Q23       Q24       Q25       Q26       Q27       Q28\n",
      "nb.repeat    1.000000   -0.056027    0.086559  0.108842 -0.071600 -0.056642  0.107333 -0.001169  0.065805 -0.027487  0.074656  0.035098  0.034777  0.049232  0.118198 -0.097082 -0.053247 -0.001297 -0.088175 -0.170159 -0.109463 -0.122571 -0.037569 -0.029491 -0.016230 -0.079884 -0.080470 -0.065697 -0.002174 -0.026205 -0.172892\n",
      "attendance  -0.056027    1.000000   -0.149757  0.114040  0.176235  0.045849  0.103250  0.043805  0.015645  0.119790  0.160856  0.135017  0.145733  0.091478  0.153556  0.084838  0.115640  0.010608  0.150936  0.065679  0.064698  0.113794  0.175960  0.185567  0.166693  0.252567  0.158154  0.146270  0.191485  0.113837  0.143246\n",
      "difficulty   0.086559   -0.149757    1.000000 -0.069618 -0.082726 -0.254037 -0.077058 -0.129680 -0.209149 -0.134010 -0.169318 -0.223523 -0.246836 -0.202521 -0.218173 -0.137313 -0.143184 -0.110896 -0.159064 -0.147113 -0.255019 -0.180980 -0.158262 -0.145640 -0.185595 -0.194302 -0.126537 -0.082578 -0.112187 -0.206941 -0.204875\n",
      "Q1           0.108842    0.114040   -0.069618  1.000000  0.688883  0.507160  0.698092  0.534788  0.344452  0.489565  0.368621  0.402436  0.499349  0.458971  0.477197  0.274041  0.314481  0.383094  0.408731  0.144236  0.275147  0.196402  0.156167  0.256071  0.215888  0.292883  0.339273  0.292247  0.312271  0.444877  0.199522\n",
      "Q2          -0.071600    0.176235   -0.082726  0.688883  1.000000  0.436573  0.569701  0.476400  0.330714  0.592181  0.387459  0.424444  0.514433  0.419751  0.438649  0.402012  0.448076  0.489087  0.548756  0.377958  0.395210  0.375835  0.297250  0.296425  0.370360  0.426475  0.367510  0.363944  0.406408  0.337145  0.337137\n",
      "Q3          -0.056642    0.045849   -0.254037  0.507160  0.436573  1.000000  0.538569  0.616354  0.560498  0.585582  0.415707  0.438165  0.647671  0.541532  0.570381  0.506943  0.536464  0.537254  0.563239  0.415434  0.524922  0.477296  0.442493  0.403619  0.432995  0.491335  0.501879  0.485623  0.600619  0.445558  0.524394\n",
      "Q4           0.107333    0.103250   -0.077058  0.698092  0.569701  0.538569  1.000000  0.619637  0.466515  0.584088  0.450828  0.367033  0.430592  0.440160  0.455282  0.316485  0.390880  0.390101  0.421541  0.173902  0.327350  0.267073  0.239458  0.273856  0.272258  0.379016  0.453531  0.334255  0.378368  0.503915  0.298285\n",
      "Q5          -0.001169    0.043805   -0.129680  0.534788  0.476400  0.616354  0.619637  1.000000  0.619032  0.737993  0.572460  0.619570  0.642335  0.612563  0.550644  0.400067  0.446061  0.478199  0.556711  0.257758  0.519316  0.381335  0.348106  0.397141  0.379401  0.495964  0.557472  0.375247  0.480269  0.440816  0.360403\n",
      "Q6           0.065805    0.015645   -0.209149  0.344452  0.330714  0.560498  0.466515  0.619032  1.000000  0.620113  0.521418  0.419275  0.567816  0.470165  0.435781  0.406486  0.511128  0.535400  0.548011  0.313317  0.478345  0.385031  0.423563  0.425061  0.428083  0.497533  0.483861  0.354025  0.500686  0.450457  0.376963\n",
      "Q7          -0.027487    0.119790   -0.134010  0.489565  0.592181  0.585582  0.584088  0.737993  0.620113  1.000000  0.686368  0.650274  0.721818  0.580056  0.584197  0.446985  0.505040  0.484230  0.540664  0.313639  0.511082  0.413574  0.369601  0.388921  0.412857  0.568568  0.538761  0.423110  0.530168  0.457242  0.356001\n",
      "Q8           0.074656    0.160856   -0.169318  0.368621  0.387459  0.415707  0.450828  0.572460  0.521418  0.686368  1.000000  0.650559  0.662677  0.562599  0.639137  0.383564  0.378325  0.323204  0.550185  0.253580  0.537422  0.386997  0.343253  0.413485  0.375601  0.523456  0.467453  0.336722  0.506812  0.509485  0.267921\n",
      "Q9           0.035098    0.135017   -0.223523  0.402436  0.424444  0.438165  0.367033  0.619570  0.419275  0.650274  0.650559  1.000000  0.761480  0.609254  0.634782  0.431117  0.470132  0.407587  0.495809  0.279585  0.562221  0.456673  0.347399  0.406492  0.410085  0.560616  0.422847  0.286069  0.478755  0.428577  0.304051\n",
      "Q10          0.034777    0.145733   -0.246836  0.499349  0.514433  0.647671  0.430592  0.642335  0.567816  0.721818  0.662677  0.761480  1.000000  0.672746  0.726397  0.533500  0.586263  0.572056  0.621206  0.439266  0.604780  0.531182  0.496461  0.512322  0.519081  0.611791  0.541853  0.429611  0.677038  0.492621  0.445228\n",
      "Q11          0.049232    0.091478   -0.202521  0.458971  0.419751  0.541532  0.440160  0.612563  0.470165  0.580056  0.562599  0.609254  0.672746  1.000000  0.804012  0.407624  0.415904  0.471141  0.491468  0.381414  0.510905  0.434283  0.340695  0.336773  0.356804  0.478212  0.509641  0.347701  0.477503  0.406336  0.300830\n",
      "Q12          0.118198    0.153556   -0.218173  0.477197  0.438649  0.570381  0.455282  0.550644  0.435781  0.584197  0.639137  0.634782  0.726397  0.804012  1.000000  0.497036  0.504824  0.481868  0.541718  0.422285  0.564713  0.426064  0.334358  0.345822  0.415244  0.535413  0.558332  0.324419  0.532447  0.504257  0.315214\n",
      "Q13         -0.097082    0.084838   -0.137313  0.274041  0.402012  0.506943  0.316485  0.400067  0.406486  0.446985  0.383564  0.431117  0.533500  0.407624  0.497036  1.000000  0.805149  0.757334  0.621320  0.481082  0.590816  0.619023  0.694624  0.583111  0.659216  0.624239  0.523822  0.548944  0.733787  0.498475  0.607639\n",
      "Q14         -0.053247    0.115640   -0.143184  0.314481  0.448076  0.536464  0.390880  0.446061  0.511128  0.505040  0.378325  0.470132  0.586263  0.415904  0.504824  0.805149  1.000000  0.838633  0.665201  0.614372  0.601374  0.657659  0.668020  0.560790  0.655925  0.635349  0.568291  0.540053  0.705633  0.472761  0.577701\n",
      "Q15         -0.001297    0.010608   -0.110896  0.383094  0.489087  0.537254  0.390101  0.478199  0.535400  0.484230  0.323204  0.407587  0.572056  0.471141  0.481868  0.757334  0.838633  1.000000  0.686060  0.561482  0.607875  0.620661  0.611735  0.598935  0.676211  0.611280  0.573422  0.589841  0.678018  0.446103  0.605135\n",
      "Q16         -0.088175    0.150936   -0.159064  0.408731  0.548756  0.563239  0.421541  0.556711  0.548011  0.540664  0.550185  0.495809  0.621206  0.491468  0.541718  0.621320  0.665201  0.686060  1.000000  0.540798  0.718703  0.663219  0.614295  0.631506  0.630554  0.693757  0.562578  0.576112  0.646445  0.537068  0.565727\n",
      "Q17         -0.170159    0.065679   -0.147113  0.144236  0.377958  0.415434  0.173902  0.257758  0.313317  0.313639  0.253580  0.279585  0.439266  0.381414  0.422285  0.481082  0.614372  0.561482  0.540798  1.000000  0.558898  0.599760  0.483579  0.421246  0.597255  0.498166  0.391144  0.530178  0.518715  0.296740  0.480115\n",
      "Q18         -0.109463    0.064698   -0.255019  0.275147  0.395210  0.524922  0.327350  0.519316  0.478345  0.511082  0.537422  0.562221  0.604780  0.510905  0.564713  0.590816  0.601374  0.607875  0.718703  0.558898  1.000000  0.800724  0.598603  0.605062  0.608685  0.667021  0.616139  0.505705  0.612282  0.565075  0.557029\n",
      "Q19         -0.122571    0.113794   -0.180980  0.196402  0.375835  0.477296  0.267073  0.381335  0.385031  0.413574  0.386997  0.456673  0.531182  0.434283  0.426064  0.619023  0.657659  0.620661  0.663219  0.599760  0.800724  1.000000  0.708356  0.641550  0.658079  0.647500  0.589630  0.540366  0.630616  0.477930  0.618821\n",
      "Q20         -0.037569    0.175960   -0.158262  0.156167  0.297250  0.442493  0.239458  0.348106  0.423563  0.369601  0.343253  0.347399  0.496461  0.340695  0.334358  0.694624  0.668020  0.611735  0.614295  0.483579  0.598603  0.708356  1.000000  0.782370  0.786580  0.715739  0.557790  0.655134  0.730438  0.454977  0.694430\n",
      "Q21         -0.029491    0.185567   -0.145640  0.256071  0.296425  0.403619  0.273856  0.397141  0.425061  0.388921  0.413485  0.406492  0.512322  0.336773  0.345822  0.583111  0.560790  0.598935  0.631506  0.421246  0.605062  0.641550  0.782370  1.000000  0.807825  0.768019  0.626136  0.713660  0.656616  0.506600  0.602925\n",
      "Q22         -0.016230    0.166693   -0.185595  0.215888  0.370360  0.432995  0.272258  0.379401  0.428083  0.412857  0.375601  0.410085  0.519081  0.356804  0.415244  0.659216  0.655925  0.676211  0.630554  0.597255  0.608685  0.658079  0.786580  0.807825  1.000000  0.768386  0.642174  0.720109  0.714759  0.485002  0.664456\n",
      "Q23         -0.079884    0.252567   -0.194302  0.292883  0.426475  0.491335  0.379016  0.495964  0.497533  0.568568  0.523456  0.560616  0.611791  0.478212  0.535413  0.624239  0.635349  0.611280  0.693757  0.498166  0.667021  0.647500  0.715739  0.768019  0.768386  1.000000  0.715947  0.705773  0.724679  0.624225  0.603788\n",
      "Q24         -0.080470    0.158154   -0.126537  0.339273  0.367510  0.501879  0.453531  0.557472  0.483861  0.538761  0.467453  0.422847  0.541853  0.509641  0.558332  0.523822  0.568291  0.573422  0.562578  0.391144  0.616139  0.589630  0.557790  0.626136  0.642174  0.715947  1.000000  0.622776  0.704811  0.621081  0.583279\n",
      "Q25         -0.065697    0.146270   -0.082578  0.292247  0.363944  0.485623  0.334255  0.375247  0.354025  0.423110  0.336722  0.286069  0.429611  0.347701  0.324419  0.548944  0.540053  0.589841  0.576112  0.530178  0.505705  0.540366  0.655134  0.713660  0.720109  0.705773  0.622776  1.000000  0.695399  0.469687  0.664733\n",
      "Q26         -0.002174    0.191485   -0.112187  0.312271  0.406408  0.600619  0.378368  0.480269  0.500686  0.530168  0.506812  0.478755  0.677038  0.477503  0.532447  0.733787  0.705633  0.678018  0.646445  0.518715  0.612282  0.630616  0.730438  0.656616  0.714759  0.724679  0.704811  0.695399  1.000000  0.624357  0.726123\n",
      "Q27         -0.026205    0.113837   -0.206941  0.444877  0.337145  0.445558  0.503915  0.440816  0.450457  0.457242  0.509485  0.428577  0.492621  0.406336  0.504257  0.498475  0.472761  0.446103  0.537068  0.296740  0.565075  0.477930  0.454977  0.506600  0.485002  0.624225  0.621081  0.469687  0.624357  1.000000  0.469799\n",
      "Q28         -0.172892    0.143246   -0.204875  0.199522  0.337137  0.524394  0.298285  0.360403  0.376963  0.356001  0.267921  0.304051  0.445228  0.300830  0.315214  0.607639  0.577701  0.605135  0.565727  0.480115  0.557029  0.618821  0.694430  0.602925  0.664456  0.603788  0.583279  0.664733  0.726123  0.469799  1.000000\n",
      "✓ Сохранено: correlation_class_3.csv и correlation_class_3.png\n",
      "\n",
      "========================================================================================================================\n",
      "МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ПРЕДМЕТА 5 (n=135)\n",
      "========================================================================================================================\n",
      "            nb.repeat  attendance  difficulty        Q1        Q2        Q3        Q4        Q5        Q6        Q7        Q8        Q9       Q10       Q11       Q12       Q13       Q14       Q15       Q16       Q17       Q18       Q19       Q20       Q21       Q22       Q23       Q24       Q25       Q26       Q27       Q28\n",
      "nb.repeat    1.000000    0.127198   -0.096773 -0.121664 -0.010729  0.011155 -0.160269 -0.116811 -0.009933 -0.022098  0.078304  0.028803  0.041137  0.005776  0.043917  0.005377 -0.085826 -0.007946 -0.015980  0.079649 -0.014718  0.010028  0.007015  0.122578  0.060839 -0.023649  0.062310 -0.013833  0.128960  0.010123  0.105656\n",
      "attendance   0.127198    1.000000   -0.041210 -0.062203 -0.027271 -0.082151 -0.057225 -0.092834 -0.060137  0.036977 -0.038779  0.084545 -0.092680  0.139659  0.076609 -0.055509 -0.042307 -0.190786 -0.127459 -0.007224 -0.008188 -0.074654 -0.134001 -0.008267 -0.055906 -0.013638 -0.120445  0.028440 -0.121255 -0.084935 -0.037405\n",
      "difficulty  -0.096773   -0.041210    1.000000  0.086726  0.200813  0.037683  0.104608  0.004803 -0.031447 -0.034184  0.016529  0.074697  0.048267 -0.079538 -0.078835  0.062551  0.127879  0.034424  0.064109  0.087704  0.128772  0.016467  0.137100 -0.007492  0.094111  0.037185  0.067324  0.127567 -0.023000  0.014853  0.075742\n",
      "Q1          -0.121664   -0.062203    0.086726  1.000000  0.564885  0.361461  0.604695  0.531305  0.305506  0.495646  0.436137  0.459043  0.413898  0.338887  0.427020  0.270277  0.108578  0.146235  0.310293  0.099875  0.323621  0.214586  0.213737  0.203751  0.225843  0.281324  0.316803  0.229960  0.133295  0.296027  0.184862\n",
      "Q2          -0.010729   -0.027271    0.200813  0.564885  1.000000  0.566560  0.562359  0.577756  0.467967  0.402610  0.422012  0.497048  0.458481  0.454903  0.428188  0.407726  0.372838  0.322374  0.443138  0.293603  0.391763  0.388325  0.437856  0.368764  0.402563  0.359084  0.366723  0.409150  0.369342  0.438460  0.390954\n",
      "Q3           0.011155   -0.082151    0.037683  0.361461  0.566560  1.000000  0.461559  0.624092  0.569350  0.466210  0.538507  0.452526  0.576251  0.481902  0.411862  0.445468  0.373658  0.398155  0.430232  0.249198  0.432504  0.391374  0.465991  0.360923  0.452017  0.372510  0.395507  0.464324  0.400907  0.406243  0.399638\n",
      "Q4          -0.160269   -0.057225    0.104608  0.604695  0.562359  0.461559  1.000000  0.503684  0.434979  0.327161  0.352052  0.372670  0.375150  0.269538  0.326513  0.385234  0.292631  0.309826  0.333582  0.263019  0.282007  0.274997  0.314209  0.284740  0.302254  0.293706  0.221583  0.325777  0.290805  0.315947  0.309772\n",
      "Q5          -0.116811   -0.092834    0.004803  0.531305  0.577756  0.624092  0.503684  1.000000  0.578650  0.573402  0.577422  0.484894  0.632410  0.379087  0.365169  0.560813  0.443589  0.426912  0.586659  0.263800  0.538180  0.530218  0.477778  0.381001  0.473382  0.500916  0.426393  0.540622  0.424314  0.536002  0.444868\n",
      "Q6          -0.009933   -0.060137   -0.031447  0.305506  0.467967  0.569350  0.434979  0.578650  1.000000  0.590554  0.540120  0.490351  0.565623  0.468858  0.403455  0.522484  0.446272  0.494420  0.519925  0.393503  0.467978  0.529287  0.475918  0.504990  0.477569  0.388956  0.320582  0.469086  0.374025  0.468859  0.449899\n",
      "Q7          -0.022098    0.036977   -0.034184  0.495646  0.402610  0.466210  0.327161  0.573402  0.590554  1.000000  0.632021  0.546409  0.620067  0.444862  0.490197  0.346624  0.260287  0.306469  0.358644  0.189408  0.475127  0.357767  0.320514  0.269202  0.371252  0.402406  0.368890  0.341088  0.287440  0.345382  0.287354\n",
      "Q8           0.078304   -0.038779    0.016529  0.436137  0.422012  0.538507  0.352052  0.577422  0.540120  0.632021  1.000000  0.652719  0.699932  0.522468  0.489039  0.338808  0.267618  0.260617  0.448619  0.149917  0.384103  0.353005  0.312040  0.274777  0.303389  0.315831  0.285270  0.276504  0.268012  0.379396  0.244513\n",
      "Q9           0.028803    0.084545    0.074697  0.459043  0.497048  0.452526  0.372670  0.484894  0.490351  0.546409  0.652719  1.000000  0.629638  0.583963  0.497261  0.370517  0.360196  0.344649  0.433128  0.292320  0.381494  0.391991  0.371331  0.309606  0.402813  0.334212  0.256707  0.390944  0.396367  0.397632  0.318457\n",
      "Q10          0.041137   -0.092680    0.048267  0.413898  0.458481  0.576251  0.375150  0.632410  0.565623  0.620067  0.699932  0.629638  1.000000  0.550168  0.569759  0.420394  0.328640  0.383237  0.508923  0.212455  0.457243  0.466534  0.345291  0.329055  0.398429  0.386029  0.341552  0.332593  0.395725  0.477240  0.308187\n",
      "Q11          0.005776    0.139659   -0.079538  0.338887  0.454903  0.481902  0.269538  0.379087  0.468858  0.444862  0.522468  0.583963  0.550168  1.000000  0.743427  0.289085  0.262666  0.225815  0.341466  0.088503  0.348691  0.323513  0.236352  0.281722  0.230935  0.225569  0.185937  0.224949  0.277045  0.352487  0.155079\n",
      "Q12          0.043917    0.076609   -0.078835  0.427020  0.428188  0.411862  0.326513  0.365169  0.403455  0.490197  0.489039  0.497261  0.569759  0.743427  1.000000  0.292321  0.213817  0.174230  0.353541  0.122379  0.388103  0.307065  0.199660  0.277773  0.269634  0.294786  0.267714  0.219081  0.234533  0.379841  0.146742\n",
      "Q13          0.005377   -0.055509    0.062551  0.270277  0.407726  0.445468  0.385234  0.560813  0.522484  0.346624  0.338808  0.370517  0.420394  0.289085  0.292321  1.000000  0.835241  0.746750  0.664638  0.579292  0.714736  0.695383  0.658229  0.634932  0.669096  0.598760  0.534987  0.669284  0.614536  0.505763  0.611148\n",
      "Q14         -0.085826   -0.042307    0.127879  0.108578  0.372838  0.373658  0.292631  0.443589  0.446272  0.260287  0.267618  0.360196  0.328640  0.262666  0.213817  0.835241  1.000000  0.722218  0.596204  0.559885  0.562937  0.613155  0.598366  0.498125  0.592672  0.454273  0.431586  0.656207  0.558494  0.463522  0.534284\n",
      "Q15         -0.007946   -0.190786    0.034424  0.146235  0.322374  0.398155  0.309826  0.426912  0.494420  0.306469  0.260617  0.344649  0.383237  0.225815  0.174230  0.746750  0.722218  1.000000  0.596505  0.655859  0.585609  0.625914  0.721452  0.583182  0.655016  0.447766  0.374228  0.609490  0.587432  0.463964  0.569211\n",
      "Q16         -0.015980   -0.127459    0.064109  0.310293  0.443138  0.430232  0.333582  0.586659  0.519925  0.358644  0.448619  0.433128  0.508923  0.341466  0.353541  0.664638  0.596204  0.596505  1.000000  0.384714  0.650943  0.650938  0.667511  0.588826  0.565267  0.558267  0.586820  0.561163  0.521698  0.634580  0.463296\n",
      "Q17          0.079649   -0.007224    0.087704  0.099875  0.293603  0.249198  0.263019  0.263800  0.393503  0.189408  0.149917  0.292320  0.212455  0.088503  0.122379  0.579292  0.559885  0.655859  0.384714  1.000000  0.511887  0.572541  0.596204  0.539854  0.642322  0.308207  0.297180  0.621806  0.436445  0.281230  0.613444\n",
      "Q18         -0.014718   -0.008188    0.128772  0.323621  0.391763  0.432504  0.282007  0.538180  0.467978  0.475127  0.384103  0.381494  0.457243  0.348691  0.388103  0.714736  0.562937  0.585609  0.650943  0.511887  1.000000  0.668993  0.647638  0.626924  0.741628  0.675901  0.669858  0.714448  0.566259  0.553044  0.599930\n",
      "Q19          0.010028   -0.074654    0.016467  0.214586  0.388325  0.391374  0.274997  0.530218  0.529287  0.357767  0.353005  0.391991  0.466534  0.323513  0.307065  0.695383  0.613155  0.625914  0.650938  0.572541  0.668993  1.000000  0.709537  0.622819  0.644748  0.567223  0.589232  0.643904  0.532124  0.596458  0.653834\n",
      "Q20          0.007015   -0.134001    0.137100  0.213737  0.437856  0.465991  0.314209  0.477778  0.475918  0.320514  0.312040  0.371331  0.345291  0.236352  0.199660  0.658229  0.598366  0.721452  0.667511  0.596204  0.647638  0.709537  1.000000  0.692833  0.653618  0.543472  0.555422  0.705333  0.577519  0.507270  0.656038\n",
      "Q21          0.122578   -0.008267   -0.007492  0.203751  0.368764  0.360923  0.284740  0.381001  0.504990  0.269202  0.274777  0.309606  0.329055  0.281722  0.277773  0.634932  0.498125  0.583182  0.588826  0.539854  0.626924  0.622819  0.692833  1.000000  0.706727  0.563922  0.571991  0.630538  0.600299  0.537159  0.624833\n",
      "Q22          0.060839   -0.055906    0.094111  0.225843  0.402563  0.452017  0.302254  0.473382  0.477569  0.371252  0.303389  0.402813  0.398429  0.230935  0.269634  0.669096  0.592672  0.655016  0.565267  0.642322  0.741628  0.644748  0.653618  0.706727  1.000000  0.629345  0.591860  0.785062  0.666590  0.525741  0.678335\n",
      "Q23         -0.023649   -0.013638    0.037185  0.281324  0.359084  0.372510  0.293706  0.500916  0.388956  0.402406  0.315831  0.334212  0.386029  0.225569  0.294786  0.598760  0.454273  0.447766  0.558267  0.308207  0.675901  0.567223  0.543472  0.563922  0.629345  1.000000  0.660184  0.603691  0.638966  0.613331  0.565523\n",
      "Q24          0.062310   -0.120445    0.067324  0.316803  0.366723  0.395507  0.221583  0.426393  0.320582  0.368890  0.285270  0.256707  0.341552  0.185937  0.267714  0.534987  0.431586  0.374228  0.586820  0.297180  0.669858  0.589232  0.555422  0.571991  0.591860  0.660184  1.000000  0.493510  0.434337  0.517322  0.481599\n",
      "Q25         -0.013833    0.028440    0.127567  0.229960  0.409150  0.464324  0.325777  0.540622  0.469086  0.341088  0.276504  0.390944  0.332593  0.224949  0.219081  0.669284  0.656207  0.609490  0.561163  0.621806  0.714448  0.643904  0.705333  0.630538  0.785062  0.603691  0.493510  1.000000  0.682196  0.544375  0.722571\n",
      "Q26          0.128960   -0.121255   -0.023000  0.133295  0.369342  0.400907  0.290805  0.424314  0.374025  0.287440  0.268012  0.396367  0.395725  0.277045  0.234533  0.614536  0.558494  0.587432  0.521698  0.436445  0.566259  0.532124  0.577519  0.600299  0.666590  0.638966  0.434337  0.682196  1.000000  0.669277  0.704030\n",
      "Q27          0.010123   -0.084935    0.014853  0.296027  0.438460  0.406243  0.315947  0.536002  0.468859  0.345382  0.379396  0.397632  0.477240  0.352487  0.379841  0.505763  0.463522  0.463964  0.634580  0.281230  0.553044  0.596458  0.507270  0.537159  0.525741  0.613331  0.517322  0.544375  0.669277  1.000000  0.566981\n",
      "Q28          0.105656   -0.037405    0.075742  0.184862  0.390954  0.399638  0.309772  0.444868  0.449899  0.287354  0.244513  0.318457  0.308187  0.155079  0.146742  0.611148  0.534284  0.569211  0.463296  0.613444  0.599930  0.653834  0.656038  0.624833  0.678335  0.565523  0.481599  0.722571  0.704030  0.566981  1.000000\n",
      "✓ Сохранено: correlation_class_5.csv и correlation_class_5.png\n",
      "\n",
      "========================================================================================================================\n",
      "МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ПРЕДМЕТА 8 (n=147)\n",
      "========================================================================================================================\n",
      "            nb.repeat  attendance  difficulty        Q1        Q2        Q3        Q4        Q5        Q6        Q7        Q8        Q9       Q10       Q11       Q12       Q13       Q14       Q15       Q16       Q17       Q18       Q19       Q20       Q21       Q22       Q23       Q24       Q25       Q26       Q27       Q28\n",
      "nb.repeat    1.000000   -0.130381   -0.155531  0.011516 -0.087929  0.124776  0.001087  0.100070  0.090135  0.114233  0.113329  0.059056  0.145455  0.114457  0.155131  0.090260  0.025437  0.055048  0.146904 -0.078924 -0.007042  0.005186 -0.037934  0.017033  0.051321  0.042137  0.057303  0.016031  0.071453  0.066733  0.063551\n",
      "attendance  -0.130381    1.000000    0.004486  0.017352  0.092073  0.059474  0.065683 -0.006601  0.005784 -0.066109 -0.093958  0.018084 -0.009690  0.029257 -0.075981  0.020485  0.143445  0.169145 -0.022861  0.088672 -0.091579  0.000503  0.056058  0.100687  0.117592  0.050070  0.040763  0.102450  0.093921  0.048313  0.094540\n",
      "difficulty  -0.155531    0.004486    1.000000  0.199212  0.082050  0.098235  0.193382  0.198546  0.016767  0.019703  0.098197  0.018985 -0.009404  0.018806  0.075945 -0.138166 -0.092522 -0.128309 -0.173959 -0.028976 -0.038273 -0.067267 -0.074897 -0.032530 -0.078778 -0.044908 -0.007824 -0.132539 -0.102626 -0.001624 -0.083988\n",
      "Q1           0.011516    0.017352    0.199212  1.000000  0.522929  0.208979  0.640806  0.466337  0.166536  0.427874  0.340545  0.139067  0.368497  0.063558  0.283758  0.265072  0.221443  0.182751  0.285592  0.038208  0.145266  0.103796  0.129137  0.088463  0.087866  0.295489  0.204188  0.062696  0.217582  0.263374  0.144031\n",
      "Q2          -0.087929    0.092073    0.082050  0.522929  1.000000  0.230411  0.526566  0.466037  0.413367  0.348060  0.380278  0.225770  0.460838  0.179092  0.286176  0.324281  0.391802  0.307556  0.337809  0.123213  0.174152  0.322983  0.302727  0.242977  0.270368  0.450241  0.312962  0.220812  0.378462  0.295461  0.266346\n",
      "Q3           0.124776    0.059474    0.098235  0.208979  0.230411  1.000000  0.213509  0.232346  0.316247  0.389454  0.302456  0.219564  0.365361  0.304163  0.294215  0.287707  0.285642  0.313635  0.275427  0.200027  0.146855  0.181069  0.139315  0.150502  0.131932  0.177889  0.170204  0.087324  0.178301  0.038132  0.188377\n",
      "Q4           0.001087    0.065683    0.193382  0.640806  0.526566  0.213509  1.000000  0.615948  0.294907  0.426934  0.384728  0.238696  0.514199  0.156549  0.352766  0.275941  0.359765  0.337502  0.333027  0.100545  0.147493  0.279385  0.230493  0.132396  0.188514  0.361471  0.342148  0.161410  0.241189  0.242302  0.212222\n",
      "Q5           0.100070   -0.006601    0.198546  0.466337  0.466037  0.232346  0.615948  1.000000  0.441818  0.472945  0.473446  0.239391  0.531093  0.259736  0.358588  0.423850  0.439701  0.352864  0.422058  0.133325  0.194352  0.282342  0.247298  0.177332  0.159783  0.383074  0.389480  0.178163  0.372858  0.341834  0.251369\n",
      "Q6           0.090135    0.005784    0.016767  0.166536  0.413367  0.316247  0.294907  0.441818  1.000000  0.488923  0.434077  0.288113  0.552746  0.229524  0.372565  0.465234  0.480161  0.442929  0.493696  0.131402  0.331717  0.349041  0.294843  0.267304  0.220013  0.330060  0.274708  0.182099  0.330739  0.194535  0.251780\n",
      "Q7           0.114233   -0.066109    0.019703  0.427874  0.348060  0.389454  0.426934  0.472945  0.488923  1.000000  0.655894  0.297287  0.526172  0.214680  0.409085  0.412182  0.331497  0.328145  0.352853  0.074438  0.249100  0.278871  0.211534  0.193707  0.133124  0.417703  0.379767  0.178536  0.318485  0.197952  0.193641\n",
      "Q8           0.113329   -0.093958    0.098197  0.340545  0.380278  0.302456  0.384728  0.473446  0.434077  0.655894  1.000000  0.314934  0.610720  0.305938  0.485031  0.414547  0.381889  0.296525  0.386271  0.037883  0.238978  0.222690  0.145588  0.125832  0.104336  0.395163  0.448271  0.178749  0.329253  0.272720  0.124904\n",
      "Q9           0.059056    0.018084    0.018985  0.139067  0.225770  0.219564  0.238696  0.239391  0.288113  0.297287  0.314934  1.000000  0.426387  0.374904  0.313501  0.330051  0.283793  0.366693  0.365794  0.178888  0.252155  0.291758  0.303256  0.283269  0.304944  0.381741  0.361377  0.279978  0.171973  0.043817  0.301653\n",
      "Q10          0.145455   -0.009690   -0.009404  0.368497  0.460838  0.365361  0.514199  0.531093  0.552746  0.526172  0.610720  0.426387  1.000000  0.479483  0.543800  0.518994  0.477970  0.485112  0.615938  0.157456  0.284851  0.422671  0.404230  0.281050  0.295094  0.485266  0.397862  0.285749  0.466566  0.346074  0.356402\n",
      "Q11          0.114457    0.029257    0.018806  0.063558  0.179092  0.304163  0.156549  0.259736  0.229524  0.214680  0.305938  0.374904  0.479483  1.000000  0.569762  0.404933  0.331429  0.382283  0.391264  0.348490  0.177515  0.283064  0.398050  0.315307  0.376476  0.245303  0.190823  0.340497  0.329561  0.190107  0.349041\n",
      "Q12          0.155131   -0.075981    0.075945  0.283758  0.286176  0.294215  0.352766  0.358588  0.372565  0.409085  0.485031  0.313501  0.543800  0.569762  1.000000  0.434694  0.361469  0.300641  0.508476  0.169145  0.288665  0.335717  0.283639  0.249592  0.223084  0.375920  0.387823  0.143171  0.310729  0.342895  0.199275\n",
      "Q13          0.090260    0.020485   -0.138166  0.265072  0.324281  0.287707  0.275941  0.423850  0.465234  0.412182  0.414547  0.330051  0.518994  0.404933  0.434694  1.000000  0.699132  0.667806  0.718865  0.343208  0.569460  0.517622  0.548215  0.442078  0.500675  0.461676  0.470595  0.412987  0.562660  0.392956  0.411749\n",
      "Q14          0.025437    0.143445   -0.092522  0.221443  0.391802  0.285642  0.359765  0.439701  0.480161  0.331497  0.381889  0.283793  0.477970  0.331429  0.361469  0.699132  1.000000  0.764968  0.644776  0.422695  0.520635  0.526149  0.577355  0.439707  0.476821  0.516937  0.488004  0.504261  0.510393  0.360156  0.434708\n",
      "Q15          0.055048    0.169145   -0.128309  0.182751  0.307556  0.313635  0.337502  0.352864  0.442929  0.328145  0.296525  0.366693  0.485112  0.382283  0.300641  0.667806  0.764968  1.000000  0.620516  0.487370  0.551144  0.527321  0.620108  0.587337  0.603355  0.560498  0.471682  0.475245  0.498354  0.267444  0.579617\n",
      "Q16          0.146904   -0.022861   -0.173959  0.285592  0.337809  0.275427  0.333027  0.422058  0.493696  0.352853  0.386271  0.365794  0.615938  0.391264  0.508476  0.718865  0.644776  0.620516  1.000000  0.328310  0.596943  0.557518  0.534901  0.468857  0.449854  0.558122  0.521709  0.395269  0.561333  0.474835  0.431621\n",
      "Q17         -0.078924    0.088672   -0.028976  0.038208  0.123213  0.200027  0.100545  0.133325  0.131402  0.074438  0.037883  0.178888  0.157456  0.348490  0.169145  0.343208  0.422695  0.487370  0.328310  1.000000  0.415181  0.382036  0.542896  0.575402  0.615240  0.358513  0.259709  0.514733  0.309098  0.306432  0.566786\n",
      "Q18         -0.007042   -0.091579   -0.038273  0.145266  0.174152  0.146855  0.147493  0.194352  0.331717  0.249100  0.238978  0.252155  0.284851  0.177515  0.288665  0.569460  0.520635  0.551144  0.596943  0.415181  1.000000  0.493327  0.439112  0.481598  0.478142  0.486769  0.533463  0.353474  0.436600  0.273161  0.335219\n",
      "Q19          0.005186    0.000503   -0.067267  0.103796  0.322983  0.181069  0.279385  0.282342  0.349041  0.278871  0.222690  0.291758  0.422671  0.283064  0.335717  0.517622  0.526149  0.527321  0.557518  0.382036  0.493327  1.000000  0.655969  0.534443  0.545879  0.563517  0.482174  0.509388  0.544034  0.378179  0.457591\n",
      "Q20         -0.037934    0.056058   -0.074897  0.129137  0.302727  0.139315  0.230493  0.247298  0.294843  0.211534  0.145588  0.303256  0.404230  0.398050  0.283639  0.548215  0.577355  0.620108  0.534901  0.542896  0.439112  0.655969  1.000000  0.645598  0.663161  0.540625  0.373943  0.621674  0.536524  0.339584  0.570003\n",
      "Q21          0.017033    0.100687   -0.032530  0.088463  0.242977  0.150502  0.132396  0.177332  0.267304  0.193707  0.125832  0.283269  0.281050  0.315307  0.249592  0.442078  0.439707  0.587337  0.468857  0.575402  0.481598  0.534443  0.645598  1.000000  0.767713  0.529358  0.411163  0.638274  0.453333  0.358573  0.699963\n",
      "Q22          0.051321    0.117592   -0.078778  0.087866  0.270368  0.131932  0.188514  0.159783  0.220013  0.133124  0.104336  0.304944  0.295094  0.376476  0.223084  0.500675  0.476821  0.603355  0.449854  0.615240  0.478142  0.545879  0.663161  0.767713  1.000000  0.579340  0.429263  0.700122  0.421021  0.358598  0.684921\n",
      "Q23          0.042137    0.050070   -0.044908  0.295489  0.450241  0.177889  0.361471  0.383074  0.330060  0.417703  0.395163  0.381741  0.485266  0.245303  0.375920  0.461676  0.516937  0.560498  0.558122  0.358513  0.486769  0.563517  0.540625  0.529358  0.579340  1.000000  0.661380  0.543088  0.533363  0.528986  0.523742\n",
      "Q24          0.057303    0.040763   -0.007824  0.204188  0.312962  0.170204  0.342148  0.389480  0.274708  0.379767  0.448271  0.361377  0.397862  0.190823  0.387823  0.470595  0.488004  0.471682  0.521709  0.259709  0.533463  0.482174  0.373943  0.411163  0.429263  0.661380  1.000000  0.407230  0.575754  0.436201  0.330209\n",
      "Q25          0.016031    0.102450   -0.132539  0.062696  0.220812  0.087324  0.161410  0.178163  0.182099  0.178536  0.178749  0.279978  0.285749  0.340497  0.143171  0.412987  0.504261  0.475245  0.395269  0.514733  0.353474  0.509388  0.621674  0.638274  0.700122  0.543088  0.407230  1.000000  0.536058  0.361538  0.596447\n",
      "Q26          0.071453    0.093921   -0.102626  0.217582  0.378462  0.178301  0.241189  0.372858  0.330739  0.318485  0.329253  0.171973  0.466566  0.329561  0.310729  0.562660  0.510393  0.498354  0.561333  0.309098  0.436600  0.544034  0.536524  0.453333  0.421021  0.533363  0.575754  0.536058  1.000000  0.488671  0.497362\n",
      "Q27          0.066733    0.048313   -0.001624  0.263374  0.295461  0.038132  0.242302  0.341834  0.194535  0.197952  0.272720  0.043817  0.346074  0.190107  0.342895  0.392956  0.360156  0.267444  0.474835  0.306432  0.273161  0.378179  0.339584  0.358573  0.358598  0.528986  0.436201  0.361538  0.488671  1.000000  0.434881\n",
      "Q28          0.063551    0.094540   -0.083988  0.144031  0.266346  0.188377  0.212222  0.251369  0.251780  0.193641  0.124904  0.301653  0.356402  0.349041  0.199275  0.411749  0.434708  0.579617  0.431621  0.566786  0.335219  0.457591  0.570003  0.699963  0.684921  0.523742  0.330209  0.596447  0.497362  0.434881  1.000000\n",
      "✓ Сохранено: correlation_class_8.csv и correlation_class_8.png\n"
     ]
    }
   ],
   "source": [
    "# Все числовые признаки\n",
    "q_cols = [f'Q{i}' for i in range(1, 29)]\n",
    "numeric_cols = ['nb.repeat', 'attendance', 'difficulty'] + q_cols # уберием class и instr (корреляция с константой)\n",
    "\n",
    "print(numeric_cols)\n",
    "\n",
    "\n",
    "# Предметы для анализа\n",
    "subjects = [3, 5, 8]\n",
    "\n",
    "for subject in subjects:\n",
    "    # Фильтрация данных по предмету\n",
    "    df_subject = df[df['class'] == subject]\n",
    "    \n",
    "    # Вычисление матрицы корреляций\n",
    "    corr_matrix = df_subject[numeric_cols].corr()\n",
    "    \n",
    "    # Текстовый вывод\n",
    "    print(f\"\\n{'='*120}\")\n",
    "    print(f\"МАТРИЦА КОРРЕЛЯЦИЙ ДЛЯ ПРЕДМЕТА {subject} (n={len(df_subject)})\")\n",
    "    print('='*120)\n",
    "    print(corr_matrix.to_string())\n",
    "    \n",
    "    # Сохранение в CSV\n",
    "    corr_matrix.to_csv(f'correlation_class_{subject}.csv')\n",
    "    \n",
    "    # Визуализация\n",
    "    plt.figure(figsize=(24, 22))\n",
    "    sns.heatmap(corr_matrix, \n",
    "                annot=True,\n",
    "                fmt='.2f',\n",
    "                cmap='coolwarm',\n",
    "                center=0,\n",
    "                vmin=-1, vmax=1,\n",
    "                square=True,\n",
    "                linewidths=0.5,\n",
    "                annot_kws={'size': 7},\n",
    "                cbar_kws={\"shrink\": 0.8})\n",
    "    \n",
    "    plt.title(f'Матрица корреляций для предмета {subject} (n={len(df_subject)})', \n",
    "              fontsize=18, pad=20, weight='bold')\n",
    "    plt.xlabel('Признаки', fontsize=14)\n",
    "    plt.ylabel('Признаки', fontsize=14)\n",
    "    plt.xticks(rotation=90, fontsize=9)\n",
    "    plt.yticks(rotation=0, fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'correlation_class_{subject}.png', dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"✓ Сохранено: correlation_class_{subject}.csv и correlation_class_{subject}.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "693c3a62-c9ed-441b-ae33-ddb59092b7e1",
   "metadata": {},
   "source": [
    "## Описательные статистики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a775467-abfd-4a5f-bdc5-2b6dd92f09f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5243339-31c5-46f3-a4a6-0cec58261af4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf83b4b-833f-4310-9594-81830700d244",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ce188a-cf70-4167-96e8-2dcf89f0f8f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563c92b6-0abf-4331-a36c-c7ae4a7f8a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "728f1316-1707-4728-851e-e85fe8140440",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
